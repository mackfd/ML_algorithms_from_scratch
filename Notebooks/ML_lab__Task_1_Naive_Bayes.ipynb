{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ff2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283999c",
   "metadata": {},
   "source": [
    "# The task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e0948",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise:</b> With the above formal description and the provided technical examples implement Naive Bayes with numpy (not using sklearn or any other framework).\n",
    "    Remember, that you just need to count the categories, iterate over all documents, collect all possible terms (words) and pre-process them (examples below).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ec8fe",
   "metadata": {},
   "source": [
    "### Class design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(BaseModel):    \n",
    "    def train(self, path):\n",
    "        pass  # This has to be implemented\n",
    "\n",
    "    def test(self, path):\n",
    "        pass  # This has to be implemented\n",
    "    \n",
    "    def predict(self, document):\n",
    "        pass  # This has to be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec516fc",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d467674",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7be3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_newsgroups = \"./newsgroups/\"\n",
    "path_newsgroups_train = os.path.join(base_path_newsgroups, \"20news-bydate-train\")\n",
    "path_newsgroups_test = os.path.join(base_path_newsgroups, \"20news-bydate-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59cadbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have <20> categories/subdirs in our training folder\n",
      "Named categories:\n",
      "\t- alt.atheism,\n",
      "\t- comp.graphics,\n",
      "\t- comp.os.ms-windows.misc,\n",
      "\t- comp.sys.ibm.pc.hardware,\n",
      "\t- comp.sys.mac.hardware,\n",
      "\t- comp.windows.x,\n",
      "\t- misc.forsale,\n",
      "\t- rec.autos,\n",
      "\t- rec.motorcycles,\n",
      "\t- rec.sport.baseball,\n",
      "\t- rec.sport.hockey,\n",
      "\t- sci.crypt,\n",
      "\t- sci.electronics,\n",
      "\t- sci.med,\n",
      "\t- sci.space,\n",
      "\t- soc.religion.christian,\n",
      "\t- talk.politics.guns,\n",
      "\t- talk.politics.mideast,\n",
      "\t- talk.politics.misc,\n",
      "\t- talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "subdirectory_names = [file_name for file_name in os.listdir(path_newsgroups_train)]\n",
    "print(\"We have <%s> categories/subdirs in our training folder\" % len(subdirectory_names))\n",
    "print(\"Named categories:\")\n",
    "print(\"\\t- \"+\",\\n\\t- \".join(sorted(subdirectory_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa193839",
   "metadata": {},
   "source": [
    "### Calling the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4e55fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance \n",
    "model = NaiveBayesClassifier()\n",
    "\n",
    "# train the instance a.k.a model\n",
    "model.train(path_newsgroups_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0b734",
   "metadata": {},
   "source": [
    "### Testing \"test\" function (full test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c4a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing <./newsgroups/20news-bydate-test>\n"
     ]
    }
   ],
   "source": [
    "# calling test for all documents from test dataset \n",
    "predictions = model.test(path_newsgroups_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32d8b79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'53417': {'alt.atheism': -1004.2773913093156,\n",
       "  'comp.graphics': -1136.0621753579267,\n",
       "  'comp.os.ms-windows.misc': -1226.033852615661,\n",
       "  'comp.sys.ibm.pc.hardware': -1148.097576641767,\n",
       "  'comp.sys.mac.hardware': -1145.137336934539,\n",
       "  'comp.windows.x': -1133.879398672583,\n",
       "  'misc.forsale': -1188.3876684286702,\n",
       "  'rec.autos': -1128.8123602315757,\n",
       "  'rec.motorcycles': -1133.5319831175282,\n",
       "  'rec.sport.baseball': -1133.3682060575777,\n",
       "  'rec.sport.hockey': -1154.4299641216624,\n",
       "  'sci.crypt': -1099.6411178657333,\n",
       "  'sci.electronics': -1144.8538186308606,\n",
       "  'sci.med': -1105.897425977385,\n",
       "  'sci.space': -1130.0437040323202,\n",
       "  'soc.religion.christian': -1102.8861916273777,\n",
       "  'talk.politics.guns': -1102.603818048012,\n",
       "  'talk.politics.mideast': -1121.696588249512,\n",
       "  'talk.politics.misc': -1108.649334060547,\n",
       "  'talk.religion.misc': -1101.5161087894655}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking up for 1 document results \n",
    "predictions[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cdfa9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4230.221928520446"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting prediction score for 1 document for 1 class from nested dictionary\n",
    "predictions[1].get('53257', {}).get('alt.atheism', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57a52ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gettting the best score for a particula document\n",
    "max(predictions[1]['53257'], key=predictions[1]['53257'].get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed70691",
   "metadata": {},
   "source": [
    "### Test \"predict\" function (1 doc passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db16d908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./newsgroups/20news-bydate-test\\\\alt.atheism\\\\53257'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constracting a path for 1 document to test \n",
    "test_category = \"alt.atheism\"\n",
    "test_category_doc = \"53257\"\n",
    "test_path = os.path.join(path_newsgroups_test, test_category, test_category_doc)\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f5f7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling predict function and passing the test path of the document \n",
    "doc_pred = model.predict(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98876a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'53257': {'alt.atheism': -4230.221928520446,\n",
       "  'comp.graphics': -4818.272546779901,\n",
       "  'comp.os.ms-windows.misc': -5183.808411626822,\n",
       "  'comp.sys.ibm.pc.hardware': -4785.74330976867,\n",
       "  'comp.sys.mac.hardware': -4803.84547348506,\n",
       "  'comp.windows.x': -4810.011048721786,\n",
       "  'misc.forsale': -5032.813797908116,\n",
       "  'rec.autos': -4685.082855672221,\n",
       "  'rec.motorcycles': -4731.667332313448,\n",
       "  'rec.sport.baseball': -4743.862466414844,\n",
       "  'rec.sport.hockey': -4754.977640991742,\n",
       "  'sci.crypt': -4604.019235083981,\n",
       "  'sci.electronics': -4789.402297402684,\n",
       "  'sci.med': -4645.464806258701,\n",
       "  'sci.space': -4698.708777752796,\n",
       "  'soc.religion.christian': -4341.661902442235,\n",
       "  'talk.politics.guns': -4554.705722081664,\n",
       "  'talk.politics.mideast': -4500.595489015951,\n",
       "  'talk.politics.misc': -4529.499217059268,\n",
       "  'talk.religion.misc': -4471.668033350638}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output of prediction for the document\n",
    "doc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eae58a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retreiving the best score \n",
    "max(doc_pred['53257'], key=doc_pred['53257'].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0ac47ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': -944.4288051567261,\n",
       " 'comp.graphics': -1019.1526713456086,\n",
       " 'comp.os.ms-windows.misc': -1106.2108527976927,\n",
       " 'comp.sys.ibm.pc.hardware': -1025.4907113859845,\n",
       " 'comp.sys.mac.hardware': -1030.019950158514,\n",
       " 'comp.windows.x': -1022.6285334798669,\n",
       " 'misc.forsale': -1079.6512448746012,\n",
       " 'rec.autos': -1014.461464205995,\n",
       " 'rec.motorcycles': -1024.091603630414,\n",
       " 'rec.sport.baseball': -1020.1295727199447,\n",
       " 'rec.sport.hockey': -1022.5993654582777,\n",
       " 'sci.crypt': -1013.0178726514542,\n",
       " 'sci.electronics': -1026.6380438748995,\n",
       " 'sci.med': -1004.8369141645849,\n",
       " 'sci.space': -1003.2701722511031,\n",
       " 'soc.religion.christian': -941.5924208695026,\n",
       " 'talk.politics.guns': -996.6109858312822,\n",
       " 'talk.politics.mideast': -981.3874707815615,\n",
       " 'talk.politics.misc': -981.818783871741,\n",
       " 'talk.religion.misc': -977.836911604625}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_pred['53257']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "da288fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate prediction lets collect the true target values into one list -> y\n",
    "y = []\n",
    "# collecting all clases from test dataset\n",
    "for class_name in os.listdir(path_newsgroups_test):\n",
    "    path_class = os.path.join(path_newsgroups_test, class_name)\n",
    "    # iteration of each document of each class via nested loop  to get to all documents of each class\n",
    "    for doc_name in os.listdir(path_class):\n",
    "        # storing class name of each document into a list of the true target values\n",
    "        y.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cc5ad74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 5438\n",
      "Incorrect: 2094\n",
      "Accuracy: 72.20%\n"
     ]
    }
   ],
   "source": [
    "# function that calculate metrics \n",
    "# we should pass y, y_hat (predictions) and name of a metric \n",
    "metrics(y,predictions,'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171dcc94",
   "metadata": {},
   "source": [
    "### Final class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe2d1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.min_count = 1\n",
    "        self.vocabulary = {}\n",
    "        self.num_docs = 0\n",
    "        self.classes = {}\n",
    "        self.priors = {}\n",
    "        self.conditionals = {}\n",
    "        self.num_docs = 0\n",
    "        #self.scores = {}\n",
    "        \n",
    "    def _tokenize_str(self, doc):\n",
    "        return re.findall(r'\\b\\w\\w+\\b', doc) # return all words with #characters > 1\n",
    "    \n",
    "    def _tokenize_file(self, doc_file):\n",
    "    # reading document and encoding\n",
    "        with codecs.open(doc_file, encoding='latin1') as doc:\n",
    "            # transforming all words into a lower register -> excluding register sensitivity \n",
    "            doc = doc.read().lower()\n",
    "            # splitting with \\n\\n\n",
    "            _header, _blankline, body = doc.partition('\\n\\n')\n",
    "            # received body we are passing to tokenize_str\n",
    "            return self._tokenize_str(body) # return all words with #characters > 1\n",
    "        \n",
    "    def train(self, path):\n",
    "        \n",
    "        #path_newsgroups_train -> path\n",
    "        for class_name in os.listdir(path):\n",
    "            # create a nested dictionary structure\n",
    "            self.classes[class_name] = {\"doc_counts\": 0, \"term_counts\": 0, \"terms\": {}}\n",
    "            #print(class_name)\n",
    "            # getting path to folders of each class \n",
    "            path_class = os.path.join(path, class_name)\n",
    "            # iteration of each document of each class via nested loop \n",
    "            for doc_name in os.listdir(path_class):\n",
    "                # calling fuction tokenize and passing a path of each folder (i.e document)\n",
    "                # as a result we will have a list of words from body of document\n",
    "                terms = self._tokenize_file(os.path.join(path_class, doc_name))\n",
    "                self.num_docs += 1\n",
    "                self.classes[class_name][\"doc_counts\"] += 1\n",
    "                # build vocabulary and count terms\n",
    "                # term is one word from list of words from one document \n",
    "                for term in terms:\n",
    "                    #print(term)\n",
    "                    self.classes[class_name][\"term_counts\"] += 1\n",
    "                    # for each class we are saving and counting how many times we see a term \n",
    "                    # in vocubulary dict it is flat dictionary -> total times we have seen a term in all documents  \n",
    "                    # in classes dict it is nested dictionary -> numbner of times we have seen a term for a class \n",
    "                    if not term in self.vocabulary:\n",
    "                        self.vocabulary[term] = 1\n",
    "                        self.classes[class_name][\"terms\"][term] = 1\n",
    "                    else:\n",
    "                        self.vocabulary[term] += 1\n",
    "                        if not term in self.classes[class_name][\"terms\"]:\n",
    "                            self.classes[class_name][\"terms\"][term] = 1\n",
    "                        else:\n",
    "                            self.classes[class_name][\"terms\"][term] += 1\n",
    "                \n",
    "         # learning function \n",
    "        for cn in self.classes:\n",
    "        # calculate priors\n",
    "        # P(C = 11) = 600/20000 --> 0.03\n",
    "        # log(P(C = 11)) = log(600)-log(20000)\n",
    "        # P(y) - prior probability of classes\n",
    "            self.priors[cn] = math.log(self.classes[cn]['doc_counts']) - math.log(self.num_docs)\n",
    "            # calculate conditionals\n",
    "            # better say P(X|y) - likelihood\n",
    "            self.conditionals[cn] = {}\n",
    "            # cdict - retrieving all words for one class \n",
    "            cdict = self.classes[cn]['terms']\n",
    "            # then take values counted for each words and summing up \n",
    "            # c_len - sum over all number of worlds of the class \n",
    "            c_len = sum(cdict.values())\n",
    "        \n",
    "            for term in self.vocabulary:\n",
    "                t_ct = 1.\n",
    "                t_ct += cdict[term] if term in cdict else 0.\n",
    "                self.conditionals[cn][term] = math.log(t_ct) - math.log(c_len + len(self.vocabulary))  \n",
    "    \n",
    "    def test(self, path_test):\n",
    "        predictions = []\n",
    "        # predict function \n",
    "        print(\"Testing <%s>\" % path_test)\n",
    "        # iterating over all classes from dictionary classes to fild documents paths \n",
    "        for class_num, class_name in enumerate(self.classes):\n",
    "            # for each class constructing path to documents: 1 doc - 1 path\n",
    "            for doc in os.listdir(os.path.join(path_test, class_name)):\n",
    "                doc_path = os.path.join(path_test, class_name, doc)\n",
    "                # once we get a path, go to tokens \n",
    "                token_list = self._tokenize_file(doc_path)\n",
    "                result = self._scores(doc, token_list)\n",
    "                predictions.append(result)\n",
    "        return predictions\n",
    "                \n",
    "    def _scores(self, doc, tokens):\n",
    "        scores = {}\n",
    "        scores[doc] = {}\n",
    "        for class_num, class_name in enumerate(self.classes):\n",
    "            scores[doc][class_name] = self.priors[class_name]\n",
    "            for term in tokens:\n",
    "                    if term in self.vocabulary:\n",
    "                        # retrieving P(x = term |y = class)\n",
    "                        # result is  P(y= class) + sum over all terms[P(x = term |y = class)]\n",
    "                        # souldn't it be log() operation ???\n",
    "                        \n",
    "                        # as a result we have \"probatility\" of a class for a given document \n",
    "                        #self.scores[doc][cn] += self.conditionals[cn][term]\n",
    "                        scores[doc][class_name] += self.conditionals[class_name][term]\n",
    "        return scores\n",
    "                \n",
    "    def predict(self, test_doc_path):\n",
    "        # retreiving doc num from given path\n",
    "        doc = test_doc_path.split('\\\\')[2]\n",
    "        # tokenizing doc \n",
    "        token_list_predict = self._tokenize_file(test_doc_path)\n",
    "        # calling score calculation for given doc \n",
    "        return self._scores(doc, token_list_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67756d",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "09b15297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y, predictions, metric_name):\n",
    "    result = []\n",
    "    y_hat = []\n",
    "    if metric_name == 'Accuracy':\n",
    "        for i in range(len(predictions)): \n",
    "            y_hat.append(max(predictions[i][list(predictions[i].keys())[0]], key=predictions[i][list(predictions[i].keys())[0]].get))\n",
    "        for i in range(len(y)):\n",
    "            result.append(int(y[i] == y_hat[i]))\n",
    "        correct = sum(result)\n",
    "        incorrect = len(y) - correct\n",
    "        print(\"Correct: {}\".format(correct))\n",
    "        print(\"Incorrect: {}\".format(incorrect))\n",
    "        print(\"Accuracy: {:2.2%}\".format(correct/len(y)))\n",
    "    else:\n",
    "        output = 'No such metric defined'\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "05719f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 5438\n",
      "Incorrect: 2094\n",
      "Accuracy: 72.20%\n"
     ]
    }
   ],
   "source": [
    "metrics(y,predictions,'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792de1c",
   "metadata": {},
   "source": [
    "### Utils implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7ee4d",
   "metadata": {},
   "source": [
    "This section cosist of appoaches for utils implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c59015",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853f34c",
   "metadata": {},
   "source": [
    "Call max(iterable, key=dict.get) with the same dictionary as both iterable and dict to find the key paired with the max value.\n",
    "\n",
    "a_dictionary = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "\n",
    "max_key = max(a_dictionary, key=a_dictionary.get)\n",
    "get key with max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bbdd424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': -944.4288051567261,\n",
       " 'comp.graphics': -1019.1526713456086,\n",
       " 'comp.os.ms-windows.misc': -1106.2108527976927,\n",
       " 'comp.sys.ibm.pc.hardware': -1025.4907113859845,\n",
       " 'comp.sys.mac.hardware': -1030.019950158514,\n",
       " 'comp.windows.x': -1022.6285334798669,\n",
       " 'misc.forsale': -1079.6512448746012,\n",
       " 'rec.autos': -1014.461464205995,\n",
       " 'rec.motorcycles': -1024.091603630414,\n",
       " 'rec.sport.baseball': -1020.1295727199447,\n",
       " 'rec.sport.hockey': -1022.5993654582777,\n",
       " 'sci.crypt': -1013.0178726514542,\n",
       " 'sci.electronics': -1026.6380438748995,\n",
       " 'sci.med': -1004.8369141645849,\n",
       " 'sci.space': -1003.2701722511031,\n",
       " 'soc.religion.christian': -941.5924208695026,\n",
       " 'talk.politics.guns': -996.6109858312822,\n",
       " 'talk.politics.mideast': -981.3874707815615,\n",
       " 'talk.politics.misc': -981.818783871741,\n",
       " 'talk.religion.misc': -977.836911604625}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][list(predictions[0].keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c70e9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = {}\n",
    "for i in range(len(predictions)): \n",
    "    y_hat[list(predictions[i].keys())[0]] =(max(predictions[i][list(predictions[i].keys())[0]], key=predictions[i][list(predictions[i].keys())[0]].get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5c13c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = []\n",
    "for i in range(len(predictions)): \n",
    "    y_hat.append(max(predictions[i][list(predictions[i].keys())[0]], key=predictions[i][list(predictions[i].keys())[0]].get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "31b7377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for class_name in os.listdir(path_newsgroups_test):\n",
    "    path_class = os.path.join(path_newsgroups_test, class_name)\n",
    "    # iteration of each document of each class via nested loop \n",
    "    for doc_name in os.listdir(path_class):\n",
    "        y.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fbd0f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 5438\n",
      "Incorrect: 2094\n",
      "Accuracy: 72.20%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(len(y)):\n",
    "    result.append(int(y[i] == y_hat[i]))\n",
    "correct = sum(result)\n",
    "incorrect = len(y) - correct\n",
    "\n",
    "print(\"Correct: {}\".format(correct))\n",
    "print(\"Incorrect: {}\".format(incorrect))\n",
    "print(\"Accuracy: {:2.2%}\".format(correct/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d73da",
   "metadata": {},
   "source": [
    "### Debugging cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33edeabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./newsgroups/20news-bydate-test\\\\alt.atheism\\\\53068'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplary_category = \"alt.atheism\"\n",
    "examplary_category_doc = \"53068\"\n",
    "exemplary_path = os.path.join(path_newsgroups_test, exemplary_category, examplary_category_doc)\n",
    "exemplary_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e3c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_str(doc):\n",
    "    return re.findall(r'\\b\\w\\w+\\b', doc) # return all words with #characters > 1\n",
    "\n",
    "def tokenize_file(doc_file):\n",
    "# reading document and encoding\n",
    "    with codecs.open(doc_file, encoding='latin1') as doc:\n",
    "        doc = doc.read().lower()\n",
    "        # splitting with \\n\\n\n",
    "        _header, _blankline, body = doc.partition('\\n\\n')\n",
    "        # received body we are passing to tokenize_str\n",
    "        return tokenize_str(body) # return all words with #characters > 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing <%s>\" % exemplary_path)\n",
    "token_list = tokenize_file(exemplary_path)\n",
    "scores = {}\n",
    "for class_num, class_name in enumerate(classes):\n",
    "    scores[class_name] = priors[class_name]\n",
    "    for term in token_list:\n",
    "        if term in vocabulary:\n",
    "            scores[class_name] += conditionals[class_name][term]\n",
    "print(scores)\n",
    "print(\"Result:\")\n",
    "print(max(scores, key=scores.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9050677",
   "metadata": {},
   "source": [
    "### Backup version of initial implementation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClass:\n",
    "    def __init__(self):\n",
    "        self.min_count = 1\n",
    "        self.vocabulary = {}\n",
    "        self.num_docs = 0\n",
    "        self.classes = {}\n",
    "        self.priors = {}\n",
    "        self.conditionals = {}\n",
    "        self.num_docs = 0\n",
    "        #self.scores = {}\n",
    "        \n",
    "    def tokenize_str(self, doc):\n",
    "        return re.findall(r'\\b\\w\\w+\\b', doc) # return all words with #characters > 1\n",
    "    \n",
    "    def tokenize_file(self, doc_file):\n",
    "    # reading document and encoding\n",
    "        with codecs.open(doc_file, encoding='latin1') as doc:\n",
    "            doc = doc.read().lower()\n",
    "            # splitting with \\n\\n\n",
    "            _header, _blankline, body = doc.partition('\\n\\n')\n",
    "            # received body we are passing to tokenize_str\n",
    "            return self.tokenize_str(body) # return all words with #characters > 1\n",
    "        \n",
    "    def train(self, path):\n",
    "        \n",
    "        #path_newsgroups_train -> path\n",
    "        for class_name in os.listdir(path):\n",
    "            # create a nested dictionary structure\n",
    "            self.classes[class_name] = {\"doc_counts\": 0, \"term_counts\": 0, \"terms\": {}}\n",
    "            #print(class_name)\n",
    "            # getting path to folders (documents) of each class \n",
    "            path_class = os.path.join(path, class_name)\n",
    "            # iteration of each document of each class via nested loop \n",
    "            for doc_name in os.listdir(path_class):\n",
    "                # calling fuction tokenize and passing a path of each folder (i.e document)\n",
    "                # as a result we will have a list of words from body of document\n",
    "                terms = self.tokenize_file(os.path.join(path_class, doc_name))\n",
    "                self.num_docs += 1\n",
    "                self.classes[class_name][\"doc_counts\"] += 1\n",
    "                # build vocabulary and count terms\n",
    "                # term is one word from list of words from one document \n",
    "                for term in terms:\n",
    "                    #print(term)\n",
    "                    self.classes[class_name][\"term_counts\"] += 1\n",
    "                    # for each class we are saving and counting how many times we see a term \n",
    "                    # in vocubulary dict it is flat dictionary -> total times we have seen a term in all documents  \n",
    "                    # in classes dict it is nested dictionary -> numbner of times we have seen a term for a class \n",
    "                    if not term in self.vocabulary:\n",
    "                        self.vocabulary[term] = 1\n",
    "                        self.classes[class_name][\"terms\"][term] = 1\n",
    "                    else:\n",
    "                        self.vocabulary[term] += 1\n",
    "                        if not term in self.classes[class_name][\"terms\"]:\n",
    "                            self.classes[class_name][\"terms\"][term] = 1\n",
    "                        else:\n",
    "                            self.classes[class_name][\"terms\"][term] += 1\n",
    "                \n",
    "         # learning function \n",
    "        for cn in self.classes:\n",
    "        # calculate priors\n",
    "        # P(C = 11) = 600/20000 --> 0.03\n",
    "        # log(P(C = 11)) = log(600)-log(20000)\n",
    "        # P(y) - prior probability of classes\n",
    "            self.priors[cn] = math.log(self.classes[cn]['doc_counts']) - math.log(self.num_docs)\n",
    "            # calculate conditionals\n",
    "            # better say P(X|y) - likelihood\n",
    "            self.conditionals[cn] = {}\n",
    "            # cdict - retrieving all words for one class \n",
    "            cdict = self.classes[cn]['terms']\n",
    "            # then take values counted for each words and summing up \n",
    "            # c_len - sum over all number of worlds of the class \n",
    "            c_len = sum(cdict.values())\n",
    "        \n",
    "            for term in self.vocabulary:\n",
    "                t_ct = 1.\n",
    "                t_ct += cdict[term] if term in cdict else 0.\n",
    "                self.conditionals[cn][term] = math.log(t_ct) - math.log(c_len + len(self.vocabulary))  \n",
    "    def predict(self, path_test):\n",
    "        # predict function \n",
    "        print(\"Testing <%s>\" % path_test)\n",
    "        # iterating over all classes from dictionary\n",
    "        for class_num, class_name in enumerate(self.classes):\n",
    "            # for each class constructing path to documents: 1 doc - 1 path\n",
    "            for doc in os.listdir(os.path.join(path_test, class_name)):\n",
    "                print(doc)\n",
    "                doc_path = os.path.join(path_test, class_name, doc)\n",
    "                # passing path of one document to func tokenize_file to get list of tokens \n",
    "                token_list = self.tokenize_file(doc_path)\n",
    "                scores = {}\n",
    "                #self.scores[doc] = {}\n",
    "                # calculate posterior probability of each class given a document \n",
    "                # P(y|X = document) \n",
    "                for class_num, class_name in enumerate(self.classes):\n",
    "                    # P(y) - prior probability of the class\n",
    "                    #self.scores[doc][cn] = self.priors[cn]\n",
    "                    scores[class_name] = self.priors[class_name]\n",
    "                    # iterating over words from the given document \n",
    "                    for term in token_list:\n",
    "                        if term in self.vocabulary:\n",
    "                            # retrieving P(x = term |y = class)\n",
    "                            # result is  P(y= class) + sum over all terms[P(x = term |y = class)]\n",
    "                            # souldn't it be log() operation ???\n",
    "                            \n",
    "                            # as a result we have \"probatility\" of a class for a given document \n",
    "                            #self.scores[doc][cn] += self.conditionals[cn][term]\n",
    "                            scores[class_name] += self.conditionals[class_name][term]\n",
    "                            \n",
    "            #print(scores)\n",
    "            #print(\"Result:\")\n",
    "            #print(max(scores, key=scores.get))  \n",
    "                #return max(scores, key=scores.get)\n",
    "            return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de745b99",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part we can say related to FEATURE ENGINEERING \n",
    "# function gets body of documents and transforms it into words \n",
    "def tokenize_str(doc):\n",
    "    return re.findall(r'\\b\\w\\w+\\b', doc) # return all words with #characters > 1\n",
    "\n",
    "# this is just example what the function above is doing \n",
    "tokenize_str(\"This is a test string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895899b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically this functioin opens files and retrieves bodies of text\n",
    "# then passes to  tokenize_str where body is split by words -> future tokens\n",
    "# this part we can say related to FEATURE ENGINEERING \n",
    "def tokenize_file(doc_file):\n",
    "    # reading document and encoding\n",
    "    with codecs.open(doc_file, encoding='latin1') as doc:\n",
    "        doc = doc.read().lower()\n",
    "        # splitting with \\n\\n\n",
    "        _header, _blankline, body = doc.partition('\\n\\n')\n",
    "        # received body we are passing to tokenize_str\n",
    "        return tokenize_str(body) # return all words with #characters > 1\n",
    "\n",
    "print(tokenize_file(exemplary_path)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5afd3d",
   "metadata": {},
   "source": [
    "## Learning & predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64903c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of learning function\n",
    "\n",
    "min_count = 1\n",
    "vocabulary = {}\n",
    "num_docs = 0\n",
    "classes = {}\n",
    "priors = {}\n",
    "conditionals = {}\n",
    "\n",
    "num_docs = 0\n",
    "for class_name in os.listdir(path_newsgroups_train):\n",
    "    # create a nested dictionary structure\n",
    "    classes[class_name] = {\"doc_counts\": 0, \"term_counts\": 0, \"terms\": {}}\n",
    "    print(class_name)\n",
    "    # getting path to folders (documents) of each class \n",
    "    path_class = os.path.join(path_newsgroups_train, class_name)\n",
    "    # iteration of each document of each class via nested loop \n",
    "    for doc_name in os.listdir(path_class):\n",
    "        # calling fuction tokenize and passing a path of each folder (i.e document)\n",
    "        # as a result we will have a list of words from body of document\n",
    "        terms = tokenize_file(os.path.join(path_class, doc_name))\n",
    "\n",
    "        num_docs += 1\n",
    "        classes[class_name][\"doc_counts\"] += 1\n",
    "\n",
    "        # build vocabulary and count terms\n",
    "        # term ia one word from list of words from one document \n",
    "        for term in terms:\n",
    "            print(term)\n",
    "            classes[class_name][\"term_counts\"] += 1\n",
    "            # for each class we are saving and counting how many times we see a term \n",
    "            # in vocubulary dict it is flat dictionary -> total times we have seen a term in all documents  \n",
    "            # in classes dict it is nested dictionary -> numbner of times we have seen a term for a class \n",
    "            if not term in vocabulary:\n",
    "                vocabulary[term] = 1\n",
    "                classes[class_name][\"terms\"][term] = 1\n",
    "            else:\n",
    "                vocabulary[term] += 1\n",
    "                if not term in classes[class_name][\"terms\"]:\n",
    "                    classes[class_name][\"terms\"][term] = 1\n",
    "                else:\n",
    "                    classes[class_name][\"terms\"][term] += 1\n",
    "\n",
    "#print(\"Term counts per class:\")\n",
    "#print({name: classes[name][\"term_counts\"] for name in classes})\n",
    "#print(\"Vocabulary size:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning function \n",
    "for cn in classes:\n",
    "    # calculate priors\n",
    "    # P(C = 11) = 600/20000 --> 0.03\n",
    "    # log(P(C = 11)) = log(600)-log(20000)\n",
    "    # P(y) - prior probability of classes\n",
    "    priors[cn] = math.log(classes[cn]['doc_counts']) - math.log(num_docs)\n",
    "\n",
    "    # calculate conditionals\n",
    "    # better say P(X|y) - likelihood\n",
    "    conditionals[cn] = {}\n",
    "    # cdict - retrieving all words for one class \n",
    "    cdict = classes[cn]['terms']\n",
    "    # then take values counted for each words and summing up \n",
    "    # c_len - sum over all number of worlds of the class \n",
    "    c_len = sum(cdict.values())\n",
    "    \n",
    "    for term in vocabulary:\n",
    "        t_ct = 1.\n",
    "        t_ct += cdict[term] if term in cdict else 0.\n",
    "        conditionals[cn][term] = math.log(t_ct) - math.log(c_len + len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict function \n",
    "print(\"Testing <%s>\" % exemplary_path)\n",
    "token_list = tokenize_file(exemplary_path)\n",
    "scores = {}\n",
    "for class_num, class_name in enumerate(classes):\n",
    "    scores[class_name] = priors[class_name]\n",
    "    for term in token_list:\n",
    "        if term in vocabulary:\n",
    "            scores[class_name] += conditionals[class_name][term]\n",
    "print(scores)\n",
    "print(\"Result:\")\n",
    "print(max(scores, key=scores.get))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
